# -*- coding: utf-8 -*-
"""DL_PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pTT4pINg8qcpU0pJk_S-s8gJjIPEvfDM
"""

from google.colab import drive
drive.mount('/content/drive')

DATA_DIR = "/content/drive/MyDrive/thyroid_dataset"
print("DATA_DIR =", DATA_DIR)

import tensorflow as tf
import os

train_dir = os.path.join(DATA_DIR, "train")
val_dir   = os.path.join(DATA_DIR, "val")
test_dir  = os.path.join(DATA_DIR, "test")

print("ðŸ“‚ Training from:", train_dir)
print("ðŸ“‚ Validation from:", val_dir)
print("ðŸ“‚ Test from:", test_dir)

input_size = (224, 224)
batch_size = 16
AUTOTUNE = tf.data.AUTOTUNE

train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    labels="inferred",
    label_mode="int",
    image_size=input_size,
    batch_size=batch_size,
    shuffle=True,
    seed=42
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    val_dir,
    labels="inferred",
    label_mode="int",
    image_size=input_size,
    batch_size=batch_size,
    shuffle=False
)

test_ds = tf.keras.utils.image_dataset_from_directory(
    test_dir,
    labels="inferred",
    label_mode="int",
    image_size=input_size,
    batch_size=batch_size,
    shuffle=False
)

print("âœ… Classes:", train_ds.class_names)
print("âœ… Train/Val/Test sizes:",
      tf.data.experimental.cardinality(train_ds).numpy() * batch_size,
      tf.data.experimental.cardinality(val_ds).numpy() * batch_size,
      tf.data.experimental.cardinality(test_ds).numpy() * batch_size)

from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models, optimizers

num_classes = len(train_ds.class_names)
input_size = (224, 224, 3)

base_model = VGG16(
    weights='imagenet',
    include_top=False,
    input_shape=input_size
)

base_model.trainable = False

model = models.Sequential([
    base_model,
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.6),
    layers.Dense(num_classes, activation='sigmoid')
])

for layer in base_model.layers[-4:]:
    layer.trainable = True

model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),  # smaller LR
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])


model.summary()

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history = model.fit(train_ds, validation_data=val_ds, epochs=20, callbacks=[early_stop])

test_loss, test_accuracy = model.evaluate(test_ds)

print(f"âœ… Test Accuracy: {test_accuracy*100:.2f}%")
print(f"âœ… Test Loss: {test_loss:.4f}")

